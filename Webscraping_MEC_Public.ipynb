{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from bs4 import BeautifulSoup # For HTML parsing\n",
    "import requests # Website connections\n",
    "from time import sleep # To prevent overwhelming the server between connections\n",
    "from collections import Counter # Keep track of our term counts\n",
    "import pandas as pd # For converting results to a dataframe and bar chart plots\n",
    "import json # For parsing json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare mens vs women's clothing?\n",
    "# compare brands of items sold at mec? How many are mec specific?\n",
    "# avg review of mec branded items vs other main brands?\n",
    "# inventory of each brand?\n",
    "# % discount of each brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mec_url = 'https://www.mec.ca/en/gender/men%27s/products/clothing/c/981'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get(mec_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_page(gender, product_type, page):\n",
    "#    url = f'https://www.mec.ca/en/gender/{gender}%27s/products/{product_type}/c/981?page={page}'\n",
    "#    result = requests.get(url)\n",
    "#    return result.status_code -- use if you wanted to check the status i.e. 200\n",
    "    \n",
    "#    soup = BeautifulSoup(result.content)\n",
    "    \n",
    "#    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = get_page('men', 'clothing', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track')\\\n",
    ".get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track')\\\n",
    ".get_text(strip=True).split(' ')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get current price (sale or no sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1\n",
    "# soup.find_all('span', class_= 'company')\n",
    "\n",
    "soup.find_all(class_='price') #clearance product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_price_1 = []\n",
    "soup_page = get_page('men', 'clothing', 0)\n",
    "\n",
    "# we have products that have ['price', 'price--original'] and the current code picks up both - let's just retreive headings \n",
    "# that say 'price' which would be a len = 1\n",
    "\n",
    "for tag in soup_page.find_all(class_=\"price\"):\n",
    "    if len(tag[\"class\"]) == 1:\n",
    "        product_price_1.append(tag.get_text(strip=True).split('$')[-1])\n",
    "#    else: \n",
    "#        product_price_1.append(tag.get_text(strip=True).split('$')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_price_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_price_1 = []\n",
    "\n",
    "for page_num in tqdm(range(0, 1)):     \n",
    "    sleep(5)\n",
    "    soup_page = get_page('men', 'clothing', page_num)\n",
    "\n",
    "    for item in soup_page.find_all(class_=\"price\"):\n",
    "        if len(item[\"class\"]) != 1:\n",
    "            pass\n",
    "        else: \n",
    "            product_price_1.append(tag.get_text(strip=True).split('$')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_price_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 2\n",
    "\n",
    "\n",
    "soup.find_all(class_='price')[0].get_text(strip=True).split('$')[-1] # regular product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total number of men's products\n",
    "\n",
    "num_products = int(soup.find('p', class_='filter-group__count qa-filter-group__count').get_text(strip = True).split(' ')[0])\n",
    "\n",
    "num_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_products // 36 #to get number of pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To get a list of all men's products with current pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each page \n",
    "# add all the product names into a list \n",
    "\n",
    "\n",
    "\n",
    "product_name = []\n",
    "product_price = []\n",
    "\n",
    "    \n",
    "for page_num in tqdm(range(0, (num_products//36) + 1)):     \n",
    "    sleep(5)\n",
    "    soup_page = get_page('men', 'clothing', page_num)\n",
    "    \n",
    "    for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "        product_name.append(tag.get_text(strip=True))\n",
    "    \n",
    "    \n",
    "    for tag in soup_page.find_all(class_='price'):\n",
    "        if len(tag[\"class\"]) == 1:\n",
    "            product_price.append(tag.get_text(strip=True).split('$')[-1])\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_price) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(product_name).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_dict = dict(zip(product_name, product_price)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page.find('div', class_='facet__expand js-facet__expand').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove parentheses\n",
    "def remove_paren(soup_page):\n",
    "    brands = soup_page.find(class_='list list--links js-facet-list qa-facet-list qa-facet-list--brand').get_text(strip=True).split(')')\n",
    "    brands_only = []\n",
    "    \n",
    "    for i in brands:\n",
    "        brands_only.append(i.split('(')[0])\n",
    "        \n",
    "    brands_only_2 = []\n",
    "    \n",
    "    for i in brands_only:\n",
    "        if len(i.split(' ')) > 1 and len(i.split(' ')) < 3:\n",
    "            brands_only_2.append(i.lower())\n",
    "            \n",
    "    return brands_only_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_paren(soup_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands_only_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For brands only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page = get_page('men', 'clothing', page_num)\n",
    "\n",
    "soup.find('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track')\\\n",
    ".get_text(strip=True).split(' ')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ' '.join(soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track')[4].get_text().split(' ')[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.lower() == 'the north face'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['black diamond', 'showers pass', 'baro drywear', 'level six', 'darn tough',\n",
    "           'pearl izumi', 'b daehlie', 'ear podz', 'mustang survival', 'race face', 'united by blue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page_2 = get_page('men', 'clothing', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower = ' '.join(soup_page_2.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track')[0].get_text().split(' ')[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower.lower() in brands_only_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_brand_test = []\n",
    "for tag in soup_page_2.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "    if ' '.join(tag.get_text(strip=True).split(' ')[:3]).lower() == 'the north face':\n",
    "        product_brand_test.append(' '.join(tag.get_text(strip=True).split(' ')[:3]))\n",
    "    elif ' '.join(tag.get_text(strip=True).split(' ')[:2]).lower() in brands_only_2:\n",
    "        product_brand_test.append(' '.join(tag.get_text(strip=True).split(' ')[:2]))\n",
    "    else:\n",
    "        product_brand_test.append(tag.get_text(strip=True).split(' ')[0])\n",
    "\n",
    "print(len(product_brand_test))\n",
    "print(product_brand_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_brand = [] \n",
    "    \n",
    "for page_num in tqdm(range(0, (num_products//36) + 1)):     \n",
    "    sleep(5)\n",
    "    soup_page = get_page('men', 'clothing', page_num)\n",
    "    \n",
    "    for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "        product_brand.append(tag.get_text(strip=True).split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(product_brand).most_common(20)\n",
    "\n",
    "# note that some brands are made up of multiple strings i.e. 'The North Face'; these are not included in here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# want to get which products brands are on sale? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page = get_page('men', 'clothing', 0)\n",
    "\n",
    "# soup_page.find_all('span', class_='badge__label')\n",
    "# cannot get \n",
    "\n",
    "m = soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile')[0].span.get_text(strip=True) # .span.get_text(strip=True) #use regex to get digits only...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "o = re.findall('\\d{2}', m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(i) for i in o]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile')[6].span.get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p == 'New'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile')[6].span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount = []\n",
    "\n",
    "import re    \n",
    "    \n",
    "for page_num in tqdm(range(0, (num_products//36) + 1)):    \n",
    "    sleep(5)\n",
    "    soup_page = get_page('men', 'clothing', page_num)\n",
    "\n",
    "    for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "        if len(tag.span) > 1:\n",
    "            if tag.span.get_text(strip=True) == 'New':\n",
    "                product_discount.append(0)\n",
    "            elif tag.span.get_text(strip=True) != '':\n",
    "                discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))]\n",
    "                for num in discount:\n",
    "                    product_discount.append(num)\n",
    "            else:\n",
    "                product_discount.append(0)\n",
    "        else: \n",
    "            product_discount.append(0)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page = get_page('men', 'clothing', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = [int(i) for i in (re.findall('\\d{2}', soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile')[10].span.get_text(strip=True)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(discount[0]) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount_1 = []\n",
    "\n",
    "import re    \n",
    "    \n",
    "for page_num in tqdm(range(0, 1)):    \n",
    "    sleep(5)\n",
    "    soup_page = get_page('men', 'clothing', page_num)\n",
    "\n",
    "    for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "        try: \n",
    "            if type(([int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))])[0]) == int:\n",
    "                discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))]\n",
    "                for num in discount:\n",
    "                    product_discount_1.append(num)\n",
    "            else: \n",
    "                product_discount_1.append(0)\n",
    "        except:\n",
    "            product_discount_1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(, columns=['Current_price', 'Discount', index= product_name_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_discount = list(zip(product_name, product_discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_currentprice_discount_review = list(zip(product_price, product_discount, product_review))\n",
    "\n",
    "len(product_currentprice_discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_currentprice_discount = list(zip(product_name, product_price, product_discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_currentprice_discount #lists each product, the cost, and the discount. \n",
    "# Can use this to get the brand and discount by brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put into DafaFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(product_currentprice_discount, columns=['Current_price', 'Discount', 'Avg_Review'], index=product_name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(soup_page.find_all('div', class_='rating')[4].get_text(strip=True).split('('))[-1].split(')')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product reviews\n",
    "\n",
    "int(soup_page.find_all('div', class_='rating')[0].get_text(strip=True).split('(')[-1].split(')')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product num reviews\n",
    "\n",
    "type(int(soup_page.find_all('div', class_='rating')[10].get_text(strip=True).split('(')[-1].split(')')[0])) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_num_review = []\n",
    "\n",
    "soup_page_3 = get_page('men', 'clothing', 0)\n",
    "\n",
    "for tag in soup_page_3.find_all('div', class_='rating'):\n",
    "    try:\n",
    "        product_num_review.append(int(tag.get_text(strip=True).split('(')[-1].split(')')[0]))  \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_num_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product reviews\n",
    "type(float(soup_page.find_all('div', class_='rating')[4].get_text(strip=True).split(' ')[0])) == float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(float(soup_page.find_all('div', class_='rating')[7].get_text(strip=True).split(' ')[0])) == float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_reviews = []\n",
    "\n",
    "for tag in soup_page.find_all('div', class_='rating'):\n",
    "    if (tag.get_text(strip=True).split(' '))[0] == '':\n",
    "        pass\n",
    "    elif (tag.get_text(strip=True).split(' '))[0].lower() == 'no':\n",
    "        product_reviews.append(float(0))\n",
    "    elif type(float((tag.get_text(strip=True).split(' '))[0])) == float:\n",
    "        product_reviews.append(float((tag.get_text(strip=True).split(' '))[0]))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brands_only_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clothing value 981\n",
    "#footwear value 1184\n",
    "\n",
    "def get_page(gender, product_type, value, page):\n",
    "    url = f'https://www.mec.ca/en/gender/{gender}%27s/products/{product_type}/c/{value}?page={page}'\n",
    "    result = requests.get(url)\n",
    "#    return result.status_code -- use if you wanted to check the status i.e. 200\n",
    "    \n",
    "    soup = BeautifulSoup(result.content)\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kids value 1900\n",
    "def get_page_k(gender, value, page):\n",
    "    url = f'https://www.mec.ca/en/products/{gender}/c/{value}?page={page}'\n",
    "    result = requests.get(url)\n",
    "#    return result.status_code -- use if you wanted to check the status i.e. 200\n",
    "    \n",
    "    soup_k = BeautifulSoup(result.content)\n",
    "    \n",
    "    return soup_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_wear(product_cat, value, page):\n",
    "    url = f'https://www.mec.ca/en/products/{product_cat}/c/{value}?page={page}'\n",
    "    result = requests.get(url)\n",
    "#    return result.status_code -- use if you wanted to check the status i.e. 200\n",
    "    \n",
    "    soup_w = BeautifulSoup(result.content)\n",
    "    \n",
    "    return soup_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_wear_sc(product_cat, subcat, value, page):\n",
    "    url = f'https://www.mec.ca/en/products/{product_cat}/{subcat}/c/{value}?page={page}'\n",
    "    result = requests.get(url)\n",
    "#    return result.status_code -- use if you wanted to check the status i.e. 200\n",
    "    \n",
    "    soup_sc = BeautifulSoup(result.content)\n",
    "    \n",
    "    return soup_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_sc(gender, product_cat, subcat, value, page):\n",
    "    url = f'https://www.mec.ca/en/gender/{gender}%27s/products/{product_cat}/{subcat}/c/{value}?page={page}'\n",
    "    result = requests.get(url)\n",
    "#    return result.status_code -- use if you wanted to check the status i.e. 200\n",
    "    \n",
    "    soup_sc = BeautifulSoup(result.content)\n",
    "    \n",
    "    return soup_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_page('men', 'clothing', 981, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # For HTML parsing\n",
    "import requests # Website connections\n",
    "from time import sleep # To prevent overwhelming the server between connections\n",
    "from collections import Counter # Keep track of our term counts\n",
    "import pandas as pd # For converting results to a dataframe and bar chart plots\n",
    "import json # For parsing json\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_category = ['clothing']*451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(product_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_retrieved = [dt.today().strftime('%Y-%m-%d')] * 451"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for page_num in tqdm(range(0, (451//36)+1)):  \n",
    "#    print(page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_name = []\n",
    "#num_products = 648\n",
    "\n",
    "#for page_num in tqdm(range(0, (num_products//36)+1)):  \n",
    "#    soup_page = get_page('women','clothing', '981', page_num)\n",
    "#    for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "#        product_name.append(tag.get_text(strip=True))\n",
    "\n",
    "#len(product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_name # product name appears to be looping over the first page only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(range(0,19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#648 % 36== 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page = get_page('men', 'clothing', 981, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile')[16].span.get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "test= [int(i) for i in re.findall('\\d{2}', p)][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount = []\n",
    "\n",
    "for page_num in tqdm(range(0, 1)):    \n",
    "    sleep(2)\n",
    "    soup_page = get_page('men', 'clothing', 981, 0)\n",
    "\n",
    "    for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "            try: \n",
    "                if type(([int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))])[0]) == int:\n",
    "                    discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))][0]\n",
    "#                    for num in discount:\n",
    "                    product_discount.append(discount)\n",
    "                else: \n",
    "                    product_discount.append(0)\n",
    "            except:\n",
    "                product_discount.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mec_info(gender, product_cat, value, page):\n",
    "    \n",
    "    product_brand = []\n",
    "    product_name = []\n",
    "    product_price = []     \n",
    "    product_discount = []\n",
    "    product_review = []\n",
    "    product_num_review = []\n",
    "    brands_only = []\n",
    "    brands_only_2 = [] #for brands with 2 words\n",
    " \n",
    "    \n",
    "    soup = get_page(gender, product_cat, value, page)\n",
    "\n",
    "    num_products = int(soup.find('p', class_='filter-group__count qa-filter-group__count').get_text(strip = True).split(' ')[0])        \n",
    "    print(num_products)\n",
    "    \n",
    "    if num_products % 36 == 0:\n",
    "        num_products_1 = num_products // 36\n",
    "    else:\n",
    "        num_products_1 = num_products // 36 + 1\n",
    "    \n",
    "    product_category = [product_cat] * num_products\n",
    "    date_retrieved = [dt.today().strftime('%Y-%m-%d')] * num_products\n",
    "\n",
    "    \n",
    "    brands = soup.find(class_='list list--links js-facet-list qa-facet-list qa-facet-list--brand').get_text(strip=True).split(')')\n",
    "    \n",
    "    for i in brands:\n",
    "        brands_only.append(i.split('(')[0])\n",
    "    \n",
    "    for i in brands_only:\n",
    "        if len(i.split(' ')) > 1 and len(i.split(' ')) < 3:\n",
    "            brands_only_2.append(i.lower())\n",
    "            \n",
    "    \n",
    "    for page_num in tqdm(range(0, (num_products_1))):    \n",
    "        sleep(2)\n",
    "        soup_page = get_page(gender, product_cat, value, page_num)\n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            if ' '.join(tag.get_text(strip=True).split(' ')[:3]).lower() == 'the north face':\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:3]))\n",
    "            elif ' '.join(tag.get_text(strip=True).split(' ')[:2]).lower() in brands_only_2:\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:2]))\n",
    "            else:\n",
    "                product_brand.append(tag.get_text(strip=True).split(' ')[0])\n",
    "            \n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            product_name.append(tag.get_text(strip=True))\n",
    "          \n",
    "        \n",
    "        for tag in soup_page.find_all(class_='price'):\n",
    "            if len(tag[\"class\"]) == 1:\n",
    "                product_price.append(tag.get_text(strip=True).split('$')[-1])\n",
    "\n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "            try: \n",
    "                if type(([int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))])[0]) == int:\n",
    "                    discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))][0]\n",
    "                    product_discount.append(discount)\n",
    "                else: \n",
    "                    product_discount.append(0)\n",
    "            except:\n",
    "                product_discount.append(0)\n",
    "        \n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            if (tag.get_text(strip=True).split(' '))[0] == '':\n",
    "                pass #this is because there the class used also considers the filter buttons on the side on the page\n",
    "            elif (tag.get_text(strip=True).split(' '))[0].lower() == 'no':\n",
    "                product_review.append(float(0))\n",
    "            elif type(float((tag.get_text(strip=True).split(' '))[0])) == float:\n",
    "                product_review.append(float((tag.get_text(strip=True).split(' '))[0]))   \n",
    "                \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            try:\n",
    "                product_num_review.append(int(tag.get_text(strip=True).split('(')[-1].split(')')[0]))  \n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(len(product_name))\n",
    "    print(len(product_brand))\n",
    "    print(len(product_price))    \n",
    "    print(len(product_price))\n",
    "            \n",
    "    m = list(zip(product_brand, product_price, product_discount, product_review, \n",
    "                 product_num_review, product_category, date_retrieved))\n",
    "    df = pd.DataFrame(m, columns=['Brand','Current_price', 'Discount', \n",
    "                                  'Avg_review_outof5', 'Num_reviews', \n",
    "                                  'Product_category', 'Date_retrieved'], index= product_name) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mec_info_k(gender, value, page):\n",
    "    \n",
    "    product_brand = []\n",
    "    product_name = []\n",
    "    product_price = []     \n",
    "    product_discount = []\n",
    "    product_review = []\n",
    "    product_num_review = []\n",
    "    brands_only = []\n",
    "    brands_only_2 = [] #for brands with 2 words\n",
    " \n",
    "    \n",
    "    soup = get_page_k(gender, value, page)\n",
    "\n",
    "    num_products = int(soup.find('p', class_='filter-group__count qa-filter-group__count').get_text(strip = True).split(' ')[0])        \n",
    "    print(num_products)\n",
    "    \n",
    "    if num_products % 36 == 0:\n",
    "        num_products_1 = num_products // 36\n",
    "    else:\n",
    "        num_products_1 = num_products // 36 + 1\n",
    "    \n",
    "    product_category = [gender] * num_products\n",
    "    date_retrieved = [dt.today().strftime('%Y-%m-%d')] * num_products\n",
    "\n",
    "    \n",
    "    brands = soup.find(class_='list list--links js-facet-list qa-facet-list qa-facet-list--brand').get_text(strip=True).split(')')\n",
    "    \n",
    "    for i in brands:\n",
    "        brands_only.append(i.split('(')[0])\n",
    "    \n",
    "    for i in brands_only:\n",
    "        if len(i.split(' ')) > 1 and len(i.split(' ')) < 3:\n",
    "            brands_only_2.append(i.lower())\n",
    "            \n",
    "    \n",
    "    for page_num in tqdm(range(0, (num_products_1))):    \n",
    "        sleep(2)\n",
    "        soup_page = get_page_k(gender, value, page_num)\n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            if ' '.join(tag.get_text(strip=True).split(' ')[:3]).lower() == 'the north face':\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:3]))\n",
    "            elif ' '.join(tag.get_text(strip=True).split(' ')[:2]).lower() in brands_only_2:\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:2]))\n",
    "            else:\n",
    "                product_brand.append(tag.get_text(strip=True).split(' ')[0])\n",
    "            \n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            product_name.append(tag.get_text(strip=True))\n",
    "          \n",
    "        \n",
    "        for tag in soup_page.find_all(class_='price'):\n",
    "            if len(tag[\"class\"]) == 1:\n",
    "                product_price.append(tag.get_text(strip=True).split('$')[-1])\n",
    "\n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "            try: \n",
    "                if type(([int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))])[0]) == int:\n",
    "                    discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))][0]\n",
    "                    product_discount.append(discount)\n",
    "                else: \n",
    "                    product_discount.append(0)\n",
    "            except:\n",
    "                product_discount.append(0)\n",
    "        \n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            if (tag.get_text(strip=True).split(' '))[0] == '':\n",
    "                pass #this is because there the class used also considers the filter buttons on the side on the page\n",
    "            elif (tag.get_text(strip=True).split(' '))[0].lower() == 'no':\n",
    "                product_review.append(float(0))\n",
    "            elif type(float((tag.get_text(strip=True).split(' '))[0])) == float:\n",
    "                product_review.append(float((tag.get_text(strip=True).split(' '))[0]))   \n",
    "                \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            try:\n",
    "                product_num_review.append(int(tag.get_text(strip=True).split('(')[-1].split(')')[0]))  \n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(len(product_name))\n",
    "    print(len(product_brand))\n",
    "    print(len(product_price))    \n",
    "    print(len(product_price))\n",
    "        \n",
    "    \n",
    "    m = list(zip(product_brand, product_price, product_discount, product_review, \n",
    "                 product_num_review, product_category, date_retrieved))\n",
    "    df = pd.DataFrame(m, columns=['Brand','Current_price', 'Discount', \n",
    "                                  'Avg_review_outof5', 'Num_reviews', \n",
    "                                  'Product_category', 'Date_retrieved'], index= product_name) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mec_info_wear(product_cat, value, page):\n",
    "    \n",
    "    product_brand = []\n",
    "    product_name = []\n",
    "    product_price = []     \n",
    "    product_discount = []\n",
    "    product_review = []\n",
    "    product_num_review = []\n",
    "    brands_only = []\n",
    "    brands_only_2 = [] #for brands with 2 words\n",
    " \n",
    "    \n",
    "    soup = get_page_wear(product_cat, value, page)\n",
    "\n",
    "    num_products = int(soup.find('p', class_='filter-group__count qa-filter-group__count')\\\n",
    "                       .get_text(strip = True).split(' ')[0].replace(',',''))        \n",
    "    print(num_products)\n",
    "    \n",
    "    if num_products % 36 == 0:\n",
    "        num_products_1 = num_products // 36\n",
    "    else:\n",
    "        num_products_1 = num_products // 36 + 1\n",
    "    \n",
    "    product_category = [product_cat] * num_products\n",
    "    date_retrieved = [dt.today().strftime('%Y-%m-%d')] * num_products\n",
    "\n",
    "    \n",
    "    brands = soup.find(class_='list list--links js-facet-list qa-facet-list qa-facet-list--brand').get_text(strip=True).split(')')\n",
    "    \n",
    "    for i in brands:\n",
    "        brands_only.append(i.split('(')[0])\n",
    "    \n",
    "    for i in brands_only:\n",
    "        if len(i.split(' ')) > 1 and len(i.split(' ')) < 3:\n",
    "            brands_only_2.append(i.lower())\n",
    "            \n",
    "    \n",
    "    for page_num in tqdm(range(0, (num_products_1))):    \n",
    "        sleep(2)\n",
    "        soup_page = get_page_wear(product_cat, value, page_num)\n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            if ' '.join(tag.get_text(strip=True).split(' ')[:3]).lower() == 'the north face':\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:3]))\n",
    "            elif ' '.join(tag.get_text(strip=True).split(' ')[:2]).lower() in brands_only_2:\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:2]))\n",
    "            else:\n",
    "                product_brand.append(tag.get_text(strip=True).split(' ')[0])\n",
    "            \n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            product_name.append(tag.get_text(strip=True))\n",
    "          \n",
    "        \n",
    "        for tag in soup_page.find_all(class_='price'):\n",
    "            if len(tag[\"class\"]) == 1:\n",
    "                product_price.append(tag.get_text(strip=True).split('$')[-1])\n",
    "\n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "            try: \n",
    "                if type(([int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))])[0]) == int:\n",
    "                    discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))][0]\n",
    "                    product_discount.append(discount)\n",
    "                else: \n",
    "                    product_discount.append(0)\n",
    "            except:\n",
    "                product_discount.append(0)\n",
    "        \n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            if (tag.get_text(strip=True).split(' '))[0] == '':\n",
    "                pass #this is because there the class used also considers the filter buttons on the side on the page\n",
    "            elif (tag.get_text(strip=True).split(' '))[0].lower() == 'no':\n",
    "                product_review.append(float(0))\n",
    "            elif type(float((tag.get_text(strip=True).split(' '))[0])) == float:\n",
    "                product_review.append(float((tag.get_text(strip=True).split(' '))[0]))   \n",
    "                \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            try:\n",
    "                product_num_review.append(int(tag.get_text(strip=True).split('(')[-1].split(')')[0]))  \n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(len(product_name))\n",
    "    print(len(product_brand))\n",
    "    print(len(product_price))    \n",
    "    print(len(product_price))\n",
    "        \n",
    "    m = list(zip(product_brand, product_price, product_discount, product_review, \n",
    "                 product_num_review, product_category, date_retrieved))\n",
    "    df = pd.DataFrame(m, columns=['Brand','Current_price', 'Discount', \n",
    "                                  'Avg_review_outof5', 'Num_reviews', \n",
    "                                  'Product_category', 'Date_retrieved'], index= product_name) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "206 // 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mec_info_wear_sc(product_cat, subcat, value, page):\n",
    "    \n",
    "    product_brand = []\n",
    "    product_name = []\n",
    "    product_price = []     \n",
    "    product_discount = []\n",
    "    product_review = []\n",
    "    product_num_review = []\n",
    "    brands_only = []\n",
    "    brands_only_2 = [] #for brands with 2 words\n",
    " \n",
    "    \n",
    "    soup = get_page_wear_sc(product_cat, subcat, value, page)\n",
    "\n",
    "    num_products = int(soup.find('p', class_='filter-group__count qa-filter-group__count')\\\n",
    "                       .get_text(strip = True).split(' ')[0].replace(',',''))        \n",
    "    print(num_products)\n",
    "    \n",
    "    if num_products % 36 == 0:\n",
    "        num_products_1 = num_products // 36\n",
    "    else:\n",
    "        num_products_1 = num_products // 36 + 1\n",
    "    \n",
    "    product_category = [product_cat] * num_products\n",
    "    date_retrieved = [dt.today().strftime('%Y-%m-%d')] * num_products\n",
    "    product_subcategory = [subcat] * num_products\n",
    "\n",
    "    \n",
    "    brands = soup.find(class_='list list--links js-facet-list qa-facet-list qa-facet-list--brand').get_text(strip=True).split(')')\n",
    "    \n",
    "    for i in brands:\n",
    "        brands_only.append(i.split('(')[0])\n",
    "    \n",
    "    for i in brands_only:\n",
    "        if len(i.split(' ')) > 1 and len(i.split(' ')) < 3:\n",
    "            brands_only_2.append(i.lower())\n",
    "            \n",
    "    \n",
    "    for page_num in tqdm(range(0, (num_products_1))):    \n",
    "        sleep(2)\n",
    "        soup_page = get_page_wear_sc(product_cat, subcat, value, page_num)\n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            if ' '.join(tag.get_text(strip=True).split(' ')[:3]).lower() == 'the north face':\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:3]))\n",
    "            elif ' '.join(tag.get_text(strip=True).split(' ')[:2]).lower() in brands_only_2:\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:2]))\n",
    "            else:\n",
    "                product_brand.append(tag.get_text(strip=True).split(' ')[0])\n",
    "            \n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            product_name.append(tag.get_text(strip=True))\n",
    "          \n",
    "        \n",
    "        for tag in soup_page.find_all(class_='price'):\n",
    "            if len(tag[\"class\"]) == 1:\n",
    "                product_price.append(tag.get_text(strip=True).split('$')[-1])\n",
    "\n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "            try: \n",
    "                if type(([int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))])[0]) == int:\n",
    "                    discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))][0]\n",
    "                    product_discount.append(discount)\n",
    "                else: \n",
    "                    product_discount.append(0)\n",
    "            except:\n",
    "                product_discount.append(0)\n",
    "        \n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            if (tag.get_text(strip=True).split(' '))[0] == '':\n",
    "                pass #this is because there the class used also considers the filter buttons on the side on the page\n",
    "            elif (tag.get_text(strip=True).split(' '))[0].lower() == 'no':\n",
    "                product_review.append(float(0))\n",
    "            elif type(float((tag.get_text(strip=True).split(' '))[0])) == float:\n",
    "                product_review.append(float((tag.get_text(strip=True).split(' '))[0]))   \n",
    "                \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            try:\n",
    "                product_num_review.append(int(tag.get_text(strip=True).split('(')[-1].split(')')[0]))  \n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(len(product_name))\n",
    "    print(len(product_brand))\n",
    "    print(len(product_price))    \n",
    "    print(len(product_price))\n",
    "        \n",
    "    m = list(zip(product_brand, product_price, product_discount, product_review, \n",
    "                 product_num_review, product_category, product_subcategory, date_retrieved))\n",
    "    df = pd.DataFrame(m, columns=['Brand','Current_price', 'Discount', \n",
    "                                  'Avg_review_outof5', 'Num_reviews', \n",
    "                                  'Product_category', 'Subcategory', 'Date_retrieved'], index= product_name) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mec_info_sc(gender, product_cat, subcat, value, page):\n",
    "    \n",
    "    product_brand = []\n",
    "    product_name = []\n",
    "    product_price = []     \n",
    "    product_discount = []\n",
    "    product_review = []\n",
    "    product_num_review = []\n",
    "    brands_only = []\n",
    "    brands_only_2 = [] #for brands with 2 words\n",
    " \n",
    "    \n",
    "    soup = get_page_sc(gender, product_cat, subcat, value, page)\n",
    "\n",
    "    num_products = int(soup.find('p', class_='filter-group__count qa-filter-group__count')\\\n",
    "                       .get_text(strip = True).split(' ')[0].replace(',',''))        \n",
    "    print(num_products)\n",
    "    \n",
    "    if num_products % 36 == 0:\n",
    "        num_products_1 = num_products // 36\n",
    "    else:\n",
    "        num_products_1 = num_products // 36 + 1\n",
    "    \n",
    "    product_category = [product_cat] * num_products\n",
    "    date_retrieved = [dt.today().strftime('%Y-%m-%d')] * num_products\n",
    "    product_subcategory = [subcat] * num_products\n",
    "\n",
    "    \n",
    "    brands = soup.find(class_='list list--links js-facet-list qa-facet-list qa-facet-list--brand').get_text(strip=True).split(')')\n",
    "    \n",
    "    for i in brands:\n",
    "        brands_only.append(i.split('(')[0])\n",
    "    \n",
    "    for i in brands_only:\n",
    "        if len(i.split(' ')) > 1 and len(i.split(' ')) < 3:\n",
    "            brands_only_2.append(i.lower())\n",
    "            \n",
    "    \n",
    "    for page_num in tqdm(range(0, (num_products_1))):    \n",
    "        sleep(2)\n",
    "        soup_page = get_page_sc(gender, product_cat, subcat, value, page_num)\n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            if ' '.join(tag.get_text(strip=True).split(' ')[:3]).lower() == 'the north face':\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:3]))\n",
    "            elif ' '.join(tag.get_text(strip=True).split(' ')[:2]).lower() in brands_only_2:\n",
    "                product_brand.append(' '.join(tag.get_text(strip=True).split(' ')[:2]))\n",
    "            else:\n",
    "                product_brand.append(tag.get_text(strip=True).split(' ')[0])\n",
    "            \n",
    "        \n",
    "        for tag in soup_page.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "            product_name.append(tag.get_text(strip=True))\n",
    "          \n",
    "        \n",
    "        for tag in soup_page.find_all(class_='price'):\n",
    "            if len(tag[\"class\"]) == 1:\n",
    "                product_price.append(tag.get_text(strip=True).split('$')[-1])\n",
    "\n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "            try: \n",
    "                if type(([int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))])[0]) == int:\n",
    "                    discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))][0]\n",
    "                    product_discount.append(discount)\n",
    "                else: \n",
    "                    product_discount.append(0)\n",
    "            except:\n",
    "                product_discount.append(0)\n",
    "        \n",
    "        \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            if (tag.get_text(strip=True).split(' '))[0] == '':\n",
    "                pass #this is because there the class used also considers the filter buttons on the side on the page\n",
    "            elif (tag.get_text(strip=True).split(' '))[0].lower() == 'no':\n",
    "                product_review.append(float(0))\n",
    "            elif type(float((tag.get_text(strip=True).split(' '))[0])) == float:\n",
    "                product_review.append(float((tag.get_text(strip=True).split(' '))[0]))   \n",
    "                \n",
    "        for tag in soup_page.find_all('div', class_='rating'):\n",
    "            try:\n",
    "                product_num_review.append(int(tag.get_text(strip=True).split('(')[-1].split(')')[0]))  \n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    print(len(product_name))\n",
    "    print(len(product_brand))\n",
    "    print(len(product_price))    \n",
    "    print(len(product_price))\n",
    "        \n",
    "    m = list(zip(product_brand, product_price, product_discount, product_review, \n",
    "                 product_num_review, product_category, product_subcategory, date_retrieved))\n",
    "    df = pd.DataFrame(m, columns=['Brand','Current_price', 'Discount', \n",
    "                                  'Avg_review_outof5', 'Num_reviews', \n",
    "                                  'Product_category', 'Subcategory', 'Date_retrieved'], index= product_name) \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = mec_info('men', 'clothing', 981, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('men_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = mec_info('women','clothing', 981, 0) # Oct 15 1:36 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.to_csv('women_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the num of reviews for men and women across products\n",
    "# discounts vs ratings\n",
    "# get colour selection? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get footwear\n",
    "\n",
    "footwear = mec_info('men', 'footwear', '1184', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footwear.to_csv('men_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footwear = mec_info('women', 'footwear', '1184', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footwear.to_csv('women_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kids = mec_info_k('kids', 1900, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kids.to_csv('kids_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hike_camp = mec_info_wear('camping-and-hiking', 1549, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hike_camp.to_csv('activity_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling = mec_info_wear('cycling', 1551, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycling.to_csv('activity_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow = mec_info_wear('snow', 2067, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow.to_csv('activity_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watersports = mec_info_wear('watersports', 1550, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watersports.to_csv('activity_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "climb = mec_info_wear('climbing', 301, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climb.to_csv('activity_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subcategories in camping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hiking_kitchen = mec_info_wear_sc('camping-and-hiking', 'kitchen-and-hydration', 1267, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_kitchen.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_footwear = mec_info_wear_sc('camping-and-hiking', 'hiking-footwear', 605, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_footwear.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_clothing = mec_info_wear_sc('camping-and-hiking', 'hiking-clothing', 604, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_clothing.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_tools = mec_info_wear_sc('camping-and-hiking', 'tools-lighting-and-accessories', 277, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_tools.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_packs = mec_info_wear_sc('camping-and-hiking', 'packs', 1564, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_packs.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hiking_safety = mec_info_wear_sc('camping-and-hiking', 'health-and-safety', 1206, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_safety.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_electronics = mec_info_wear_sc('camping-and-hiking', 'electronics', 1108, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_electronics.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_tents = mec_info_wear_sc('camping-and-hiking', 'camping-tents-tarps-and-bivies', 1436, 0)\n",
    "hiking_tents.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking_sleepingbags = mec_info_wear_sc('camping-and-hiking', 'sleeping-bags-and-pads', 1405, 0)\n",
    "hiking_sleepingbags.to_csv('activitysubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subcat in clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_jacket = mec_info_sc('men', 'clothing', 'jackets', 1018, 0)\n",
    "clothing_jacket.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_bottoms = mec_info_sc('men', 'clothing', 'bottoms', 1002, 0)\n",
    "clothing_bottoms.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_tops = mec_info_sc('men', 'clothing', 'shirts-and-tops', 1044, 0)\n",
    "clothing_tops.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_hoodies = mec_info_sc('men', 'clothing', 'fleece-hoodies-and-sweaters', 271, 0)\n",
    "clothing_hoodies.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_accessories = mec_info_sc('men', 'clothing', 'clothing-accessories', 982, 0)\n",
    "clothing_accessories.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_base = mec_info_sc('men', 'clothing', 'base-layers-and-underwear', 1053, 0)\n",
    "clothing_base.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_swim = mec_info_sc('men', 'clothing', 'swimwear', 1036, 0)\n",
    "clothing_swim.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_socks = mec_info_sc('men', 'clothing', 'socks', 1203, 0)\n",
    "clothing_socks.to_csv('clothingsubcat_mec_info_{}.csv'.format(dt.today().strftime('%Y-%m-%d')), mode = 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** mec is clothing + activities\n",
    "\n",
    "- mec organizes their sites in two ways, by gender and kids and then by activities\n",
    "- if by activities some products overlap between the two, mainly on the clothing and footwear end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **womens vs mens vs kids clothing and footwear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reviews by brand - which are the most highly rated products?\n",
    "- num reviews advertised on site - either pulled directly from brand website or is a review on the mec website\n",
    "- reviews:num reviews ratio\n",
    "- what is the distribution of products sold at mec?\n",
    "- which brands go on sale more frequently? Is it bc of poor performance? \n",
    "- avg price by brand and by sex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **which activities have the most products?\n",
    "\n",
    "- which activities have the most online engagement in terms of reviews - camping, skiing, biking, watersports, climbing, running. \n",
    "- reviews:num reviews ratio\n",
    "- which activities do mec not have their own items in? Should mec have their own items in this space? i.e. they have their own bike brand, bags, clothes but not in electronics, paddleboards, pfds.....   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Women's clothes trial and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_w = get_page('women', 'clothing', page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_products_w = int(soup_w.find('p', class_='filter-group__count qa-filter-group__count').get_text(strip = True).split(' ')[0])\n",
    "\n",
    "num_products_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_products_w // 36 #to get number of pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_w = []\n",
    "product_price_w = []\n",
    "\n",
    "    \n",
    "for page_num in tqdm(range(0, (num_products_w//36) + 1)):     \n",
    "    sleep(5)\n",
    "    soup_page_w = get_page('women', 'clothing', page_num)\n",
    "    \n",
    "    for tag in soup_page_w.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "        product_name_w.append(tag.get_text(strip=True))\n",
    "    \n",
    "    \n",
    "    for tag in soup_page_w.find_all(class_='price'):\n",
    "        if len(tag[\"class\"]) == 1:\n",
    "            product_price_w.append(tag.get_text(strip=True).split('$')[-1])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_name_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_price_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(product_name_w).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_w = list(zip(product_name_w, product_price_w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_dict_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_brand_w = [] \n",
    "    \n",
    "for page_num in tqdm(range(0, (num_products_w//36) + 1)):     \n",
    "    sleep(5)\n",
    "    soup_page_w = get_page('women', 'clothing', page_num)\n",
    "    \n",
    "    for tag in soup_page_w.find_all('a', class_='product__name__link qa-product__name__link js-grid-url js-product-click-track-link js-product-view-track'):\n",
    "        product_brand_w.append(tag.get_text(strip=True).split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_brand_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(product_brand_w).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# want to get which products brands are on sale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_discount_w = []\n",
    "\n",
    "import re    \n",
    "    \n",
    "for page_num in tqdm(range(0, (num_products_w//36) + 1)):    \n",
    "    sleep(5)\n",
    "    soup_page_w = get_page('women', 'clothing', page_num)\n",
    "\n",
    "    for tag in soup_page_w.find_all('div', class_='flexigrid__tile js-plp-with-takeovers__tile qa-plp-with-takeovers__tile'):\n",
    "        if len(tag.span) > 1:\n",
    "            if tag.span.get_text(strip=True) == 'New':\n",
    "                product_discount_w.append(0)\n",
    "            elif tag.span.get_text(strip=True) != '':\n",
    "                discount = [int(i) for i in (re.findall('\\d{2}', tag.span.get_text(strip=True)))]\n",
    "                for num in discount:\n",
    "                    product_discount_w.append(num)\n",
    "            else:\n",
    "                product_discount_w.append(0)\n",
    "        else: \n",
    "            product_discount_w.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product_discount_w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name_currentprice_discount_w = list(zip(product_name_w, product_price_w, product_discount_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhaps more of the mec branded items are on sale vs other brands. What does this suggest? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# want to know reviews by brand\n",
    "# want to get how the products are assorted - jackets, bottoms, etc - maybe in the future"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
